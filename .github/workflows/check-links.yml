name: Check links of  d-bl repos

on:
  workflow_dispatch:

jobs:
  download-assets:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - repo: d-bl.github.io
            index: 0
          - repo: GroundForge
            index: 1
          - repo: GroundForge-help
            index: 2
          - repo: MAE-gf
            index: 3
          - repo: tesselace-to-gf
            index: 4
          - repo: gw-lace-to-gf
            index: 5
          - repo: inkscape-bobbinlace
            index: 6
          - repo: polar-grids
            index: 7
    steps:
      - name: wait
        run: sleep $(( ${{ matrix.index }} * 60 ))

      - name: Get latest successful run ID for ${{ matrix.repo }}
        id: get_run_id
        run: |
          run_id=$(gh run list --repo d-bl/${{ matrix.repo }} --workflow pages-build-deployment --status success --limit 1 --json databaseId -q '.[0].databaseId')
          echo "run_id=$run_id" >> $GITHUB_OUTPUT
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Download github-pages artifact of ${{ matrix.repo }}
        uses: actions/download-artifact@v5
        with:
          repository: d-bl/${{ matrix.repo }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ steps.get_run_id.outputs.run_id }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Untar downloaded artifact of ${{ matrix.repo }}
        run: tar -xf artifact.tar

      - name: List extracted files of ${{ matrix.repo }}
        run: |
          pwd
          ls -R ../..

      - name: Get script
        run: |
          wget https://raw.githubusercontent.com/d-bl/d-bl.github.io/refs/heads/master/urls.py

      - name: Collect URLs from extracted HTML pages
        run: |
          python extract-links.py ${{ matrix.repo }} > collected-urls.txt
        shell: bash

      - name: Show collected urls
        run: cat collected-urls.txt

      - name: Show problematic URLs
        run: |
          xargs -I {} bash -c 'curl -s -o /dev/null -w "%{http_code}" "{}" ; echo " " {} ; sleep 1' \ 
            < collected-urls.txt | grep -v '301  ' | grep -v '200  '
